bin_coef <- tidy(bin_mod)
bin_coef$model <- "binomial"
#extract gamma coefficients
gamma_coef <- tidy(gamma_mod)
gamma_coef$model <- "gamma"
mod <- rbind(gamma_coef, bin_coef)
#the probabiliy of the NULL hypothesis where ASV integrals are the same between groups is dependent on the probability of the
#NULL hypothesis that groups do not have an effect on the presence or absence of an ASV, so the p value from the
#binomial model is multiplied by the p value of the gamma model
combined_pval <- tibble(p.value = bin_coef$p.value * gamma_coef$p.value, model = "hurdle",
term = gamma_coef$term, estimate = NA, std.error = NA, statistic = NA)
#combine p_values and OTU into a data.frame
mod <- rbind(mod, combined_pval)
}
compute_CI <- function(x, i){
x <- x[i, ]
#fit a binomial logistic regression with the binary presence or absense as the response
# to predict the probability of an ASV being present during the timecourse
bin_mod <- glm(formula = bin_model, data = x, family = binomial(link = logit))
#fit a gamma GLM to the integral values
gamma_mod <- glm(formula = gamma_model, data = subset(x, non_zero==1),
family = Gamma(link = "log"))
if (is.null(variable)){
bin_coef <- tidy(bin_mod)
gamma_coef <- tidy(gamma_mod)
} else if (!is.null(variable)){
bin_coef <- tidy(bin_mod)
bin_coef <- bin_coef[-1,]
gamma_coef <- tidy(gamma_mod)
gamma_coef <- gamma_coef[-1,]
}
bin_est <- plogis(bin_coef$estimate)
gamma_est <- exp(gamma_coef$estimate)
exp(log(bin_est) + log(gamma_est))
}
#iterate model across the list
mod_list <- lapply(seqmat_integrals_list, bin_gamma_hurdle)
#determine if we are comparing OTU means or cluster means
cluster_or_OTU <- lapply(seqmat_integrals_list, function(x) colnames(x)=="cluster")
cluster_or_OTU <- do.call("rbind", cluster_or_OTU)
#set a variable to join the model dataframes and CI dataframes based on whether it is clusters or OTUs
if (any(cluster_or_OTU==TRUE)==TRUE){
name_variable <- "cluster"
} else if (any(cluster_or_OTU==TRUE)==FALSE){
name_variable <- "OTU"
}
#create list of OTU or cluster names to eventually join the mod list to the CI list
names_df <- data.frame(names(mod_list))
colnames(names_df)[1] <- name_variable
names_list <- split(names_df, f = as.factor(names_df[,name_variable]))
#combine names to mod list dataframes and then melt into longform. Then rename columns in each dataframe
mod_list <- Map(f = cbind, mod_list, names_list)
#compute an adjusted p value for FDR for each model p value
mod_list_binomial <- lapply(mod_list, function(x) subset(x, model=="binomial"))
mod_list_binomial <- do.call("rbind", mod_list_binomial)
mod_list_binomial$padj <- p.adjust(p = mod_list_binomial$p.value, method = "BH")
mod_list_gamma <- lapply(mod_list, function(x) subset(x, model=="gamma"))
mod_list_gamma <- do.call("rbind", mod_list_gamma)
mod_list_gamma$padj <- p.adjust(p = mod_list_gamma$p.value, method = "BH")
mod_list_hurdle <- lapply(mod_list, function(x) subset(x, model=="hurdle"))
mod_list_hurdle <- do.call("rbind", mod_list_hurdle)
mod_list_hurdle$padj <- p.adjust(p = mod_list_hurdle$p.value, method = "BH")
mod_list_padj <- rbind(mod_list_binomial, mod_list_gamma, mod_list_hurdle)
mod_list_padj <- mod_list_padj[,c("model", name_variable, "padj")]
mod_list_padj <- split(mod_list_padj, f = as.factor(mod_list_padj[,name_variable]))
return(mod_list_padj)
if (calc_CI == TRUE){
#iterate bootstrap function across list, calculate and extract CI
CI_list <- lapply(seqmat_integrals_list, boot, compute_CI, R = boot_k)
CI_list <- lapply(CI_list, boot.ci, type = "bca")
CI_list <- lapply(CI_list, function(x) x <- data.frame(lower_bound = x$bca[4], upper_bound = x$bca[5]))
#create list of OTU or cluster names to eventually join the CI list to the model list
names_df <- data.frame(names(CI_list))
colnames(names_df)[1] <- name_variable
names_list <- split(names_df, f = as.factor(names_df[,name_variable]))
#combine names to CI list dataframes and then melt into longform. Then rename columns in each dataframe
CI_list <- Map(f = cbind, CI_list, names_list)
#join the model list and CI list by OTU/cluster names
mod_list <- Map(f = left_join, by = name_variable, mod_list, CI_list)
}
mod_df <- do.call("rbind", mod_list)
}
test_mod_list <- compare_pd(asv_list = test,boot_k = 1000,calc_CI = TRUE)
View(test_mod_list)
compare_pd <- function(asv_list, batch=FALSE, comparison=FALSE, calc_CI=FALSE, boot_k=NULL,groups=NULL){
#set object
seqmat_integrals_list <- asv_list$seqmat_integrals
#function to remove ASVs that are zero across all samples in a variable level
remove_zero_ASVs <- function(x,variable){
#create variable for whether or not an ASV is present in a sample
x$non_zero <- ifelse(x$value > 0, 1, 0)
#for the gamma distribution to model the continuous response variable of ASV population
#during a timecourse (quantified by the integral of the abundance curve), we remove samples which
#have an integral of zero
non_zero_only <- subset(x, non_zero==1)
non_zero_only[] <- lapply(non_zero_only, function(x) if(is.factor(x)) factor(x) else x)
#this control flow step sets dataframes within a list to NULL if one factor level is all 0 values
if (length(levels(non_zero_only[,variable])) <= length(levels(x[,variable])) - 1) {
return(NULL)
} else if (length(levels(non_zero_only[,variable])) == length(levels(x[,variable]))){
return(x)
}
}
#remove ASVs where there is a variable level that contains all 0 values for the integral if comparison is chosen
if (comparison == TRUE){
if (batch == FALSE){
seqmat_integrals_list <- lapply(seqmat_integrals_list, remove_zero_ASVs, variable = "independent_var")
} else if (batch == TRUE){
seqmat_integrals_list <- lapply(seqmat_integrals_list, remove_zero_ASVs, variable = "independent_var")
seqmat_integrals_list <- lapply(seqmat_integrals_list, remove_zero_ASVs, variable = "batch")
}
seqmat_integrals_list <- seqmat_integrals_list[lapply(seqmat_integrals_list, is.null)==FALSE]
} else if (comparison == FALSE){
seqmat_integrals_list <- lapply(seqmat_integrals_list, function(x) cbind(x, non_zero = ifelse(x$value > 0, 1, 0)))
}
#set variable names for bootstrap repetition check function
if (calc_CI == TRUE){
if (comparison == FALSE){
variable <- NULL
} else if (comparison == TRUE){
if (batch == FALSE){
variable <- "independent_var"
} else if (batch == TRUE){
variable <- "batch"
}
}
boot_k <- boot_k
#returns TRUE if sample size is sufficient for number of selected bootstraps, FALSE if not
validate_reps <- function(x,variable){
#remove rows which are zero
x <- x[x$value > 0,]
if (is.null(variable)){
#group by variable, then tally sample size by group
x <- x %>%
tally()
} else if (!is.null(variable)){
#set column name for grouping
colnames(x)[colnames(x) == variable] <- "variable"
#group by variable, then tally sample size by group
x <- x %>%
group_by(variable) %>%
tally()
}
#return logical of whether sample size is too low for R bootstraps
x <- boot_k < choose(2*x$n - 1, x$n)
x
}
#iterate on seqmat_integrals
boot_check_list <- lapply(seqmat_integrals_list, validate_reps, variable=variable)
boot_check <- boot_check_list[lapply(boot_check_list, function(x) any(x == FALSE))==TRUE]
if (length(boot_check) > 0){
message("One or more response variables have an insufficient sample size for selected number of bootstraps.
Returning a vector of response variables with insufficient sample size")
return(asv_vector <- names(boot_check))
} else if (length(boot_check) == 0){
}
}
#flow control for creating a model formula
if (comparison == FALSE){
bin_model <- non_zero ~ 1
gamma_model <- value ~ 1
} else if (comparison == TRUE){
if (batch == FALSE){
bin_model <- non_zero ~ independent_var
gamma_model <- value ~ independent_var
} else if (batch == TRUE){
bin_model <- non_zero ~ independent_var + batch
gamma_model <- value ~ independent_var + batch
}
}
#if a comparison vector is provided subset the variable to those two levels
if (is.null(groups)){
seqmat_integrals_list
} else if (!is.null(groups)){
seqmat_integrals_list <- lapply(seqmat_integrals_list, subset, independent_var==groups)
#reorder the factor in the order provided in the comparison vector
seqmat_integrals_list <- lapply(seqmat_integrals_list, function (x) x$independent_var <- factor(x$independent_var,
levels = groups))
}
#create a function for the model to iterate across the list
bin_gamma_hurdle <- function(x){
#fit a binomial logistic regression with the binary presence or absense as the response
# to predict the probability of an ASV being present during the timecourse
bin_mod <- glm(formula = bin_model, data = x, family = binomial(link = logit))
#fit a gamma GLM to the integral values
gamma_mod <- glm(formula = gamma_model, data = subset(x, non_zero==1),
family = Gamma(link = "log"))
#extract binomial model coefficients
bin_coef <- tidy(bin_mod)
bin_coef$model <- "binomial"
#extract gamma coefficients
gamma_coef <- tidy(gamma_mod)
gamma_coef$model <- "gamma"
mod <- rbind(gamma_coef, bin_coef)
#the probabiliy of the NULL hypothesis where ASV integrals are the same between groups is dependent on the probability of the
#NULL hypothesis that groups do not have an effect on the presence or absence of an ASV, so the p value from the
#binomial model is multiplied by the p value of the gamma model
combined_pval <- tibble(p.value = bin_coef$p.value * gamma_coef$p.value, model = "hurdle",
term = gamma_coef$term, estimate = NA, std.error = NA, statistic = NA)
#combine p_values and OTU into a data.frame
mod <- rbind(mod, combined_pval)
}
compute_CI <- function(x, i){
x <- x[i, ]
#fit a binomial logistic regression with the binary presence or absense as the response
# to predict the probability of an ASV being present during the timecourse
bin_mod <- glm(formula = bin_model, data = x, family = binomial(link = logit))
#fit a gamma GLM to the integral values
gamma_mod <- glm(formula = gamma_model, data = subset(x, non_zero==1),
family = Gamma(link = "log"))
if (is.null(variable)){
bin_coef <- tidy(bin_mod)
gamma_coef <- tidy(gamma_mod)
} else if (!is.null(variable)){
bin_coef <- tidy(bin_mod)
bin_coef <- bin_coef[-1,]
gamma_coef <- tidy(gamma_mod)
gamma_coef <- gamma_coef[-1,]
}
bin_est <- plogis(bin_coef$estimate)
gamma_est <- exp(gamma_coef$estimate)
exp(log(bin_est) + log(gamma_est))
}
#iterate model across the list
mod_list <- lapply(seqmat_integrals_list, bin_gamma_hurdle)
#determine if we are comparing OTU means or cluster means
cluster_or_OTU <- lapply(seqmat_integrals_list, function(x) colnames(x)=="cluster")
cluster_or_OTU <- do.call("rbind", cluster_or_OTU)
#set a variable to join the model dataframes and CI dataframes based on whether it is clusters or OTUs
if (any(cluster_or_OTU==TRUE)==TRUE){
name_variable <- "cluster"
} else if (any(cluster_or_OTU==TRUE)==FALSE){
name_variable <- "OTU"
}
#create list of OTU or cluster names to eventually join the mod list to the CI list
names_df <- data.frame(names(mod_list))
colnames(names_df)[1] <- name_variable
names_list <- split(names_df, f = as.factor(names_df[,name_variable]))
#combine names to mod list dataframes and then melt into longform. Then rename columns in each dataframe
mod_list <- Map(f = cbind, mod_list, names_list)
#compute an adjusted p value for FDR for each model p value
mod_list_binomial <- lapply(mod_list, function(x) subset(x, model=="binomial"))
mod_list_binomial <- do.call("rbind", mod_list_binomial)
mod_list_binomial$padj <- p.adjust(p = mod_list_binomial$p.value, method = "BH")
mod_list_gamma <- lapply(mod_list, function(x) subset(x, model=="gamma"))
mod_list_gamma <- do.call("rbind", mod_list_gamma)
mod_list_gamma$padj <- p.adjust(p = mod_list_gamma$p.value, method = "BH")
mod_list_hurdle <- lapply(mod_list, function(x) subset(x, model=="hurdle"))
mod_list_hurdle <- do.call("rbind", mod_list_hurdle)
mod_list_hurdle$padj <- p.adjust(p = mod_list_hurdle$p.value, method = "BH")
mod_list_padj <- rbind(mod_list_binomial, mod_list_gamma, mod_list_hurdle)
mod_list_padj <- mod_list_padj[,c("model", name_variable, "padj")]
mod_list_padj <- split(mod_list_padj, f = as.factor(mod_list_padj[,name_variable]))
mod_list_padj <- lapply(mod_list_padj, function(x) x[!names(x) %in% name_variable])
mod_list <- Map(left_join, mod_list, mod_list_padj, by = "model")
return(mod_list)
if (calc_CI == TRUE){
#iterate bootstrap function across list, calculate and extract CI
CI_list <- lapply(seqmat_integrals_list, boot, compute_CI, R = boot_k)
CI_list <- lapply(CI_list, boot.ci, type = "bca")
CI_list <- lapply(CI_list, function(x) x <- data.frame(lower_bound = x$bca[4], upper_bound = x$bca[5]))
#create list of OTU or cluster names to eventually join the CI list to the model list
names_df <- data.frame(names(CI_list))
colnames(names_df)[1] <- name_variable
names_list <- split(names_df, f = as.factor(names_df[,name_variable]))
#combine names to CI list dataframes and then melt into longform. Then rename columns in each dataframe
CI_list <- Map(f = cbind, CI_list, names_list)
#join the model list and CI list by OTU/cluster names
mod_list <- Map(f = left_join, by = name_variable, mod_list, CI_list)
}
mod_df <- do.call("rbind", mod_list)
}
test_mod_list <- compare_pd(asv_list = test,boot_k = 1000,calc_CI = TRUE)
test_mod_list$`1`
load("../../../Downloads/Hannah_Dogs_current_210.RData")
Dog_asv_richness_pie
Dog_asv_abundance_pie
bar
Dog_asv_richness_pie
Dog_asv_abundance_pie
library(phyloseq)
library(tidyverse)
#'make asv pie chart. i repurposed  my pie chart function from omu to work with the output
#' of ASV_richness_table
asv_pie_chart <- function(ratio_data,x_variable, fill_variable, y_variable, color){
#' create a bar plot of the data
bar<- ggplot(ratio_data)+
geom_bar(width = 1,aes(x=ratio_data[,x_variable], y=ratio_data[,y_variable], fill=ratio_data[,fill_variable]),
stat = "identity", color = color) + facet_wrap(.~ratio_data[,x_variable], scales = "free")
#'ggplot2s coord_polar function has weird behavior with facet_wrap free scales so we need to
#'create a new coord_polar function
cp <- coord_polar(theta = "y")
cp$is_free <- function() TRUE
#' create the pie chart by adding the new coord polar function as a layer, clean it up by adding
#' additional layers to remove coordinates, axis ticks, etc
pie <- bar + cp +
theme_bw() + theme(panel.border = element_blank()) +
theme(panel.grid = element_blank()) +
theme(axis.text = element_blank()) +
theme(axis.title = element_blank()) +
theme(axis.ticks = element_blank())
return(pie)
}
ASV_richness_table <- function(df, taxrank, ratio, metadata, variable){
#' define objects in function env and select numeric values for replacement
df = df
taxrank = taxrank
df[,taxrank] = as.character(df[,taxrank])
vars <- select_if(df, is.numeric)
vars <- colnames(vars)
replace_values <- function(x,df,taxrank){
ifelse(x == 0, x, df[,taxrank])
}
#'replace above zero values with taxanomic names to establish presence vs absence
df <- df %>% mutate_if(is.numeric, replace_values, df = df, taxrank = taxrank)
df <- df[,vars]
#' generate a list of count tables for each sample
freq_table <- apply(df[-1,], 2, table)
#'turn list inside out and make count table dataframe
nms <- freq_table %>% map(names) %>% purrr::reduce(union)
freq_table <- freq_table %>% transpose(.names = nms)
freq_table <- data.frame(t(sapply(freq_table,c)))
#'remove 0 counts and NULL values
remove_row <- "0"
freq_table <- freq_table[!(row.names(freq_table) %in% remove_row), ]
freq_table[freq_table=='NULL'] <- 0
#'convert lists to numeric vectors
freq_mat <- as.data.frame(sapply(freq_table, as.numeric))
rownames(freq_mat) <- rownames(freq_table)
#'caluclate frequencies or return absolute ASV counts
if (ratio==FALSE){
ratio_mat = freq_mat} else if (ratio==TRUE){
calculate_ratio <- function(x){
x <- x/sum(x)
return(x)
}
ratio_mat <- freq_mat %>% mutate_if(is.numeric, calculate_ratio)
}
rownames(ratio_mat) <- rownames(freq_mat)
ratio_mat <- t(ratio_mat)
#' average by an experimental variable or move forward with individual samples
ratio_mat<- cbind(ratio_mat, metadata)
if (missing(variable)){
ratio_mat=ratio_mat
ratio_mat$Samples <- rownames(ratio_mat)
} else {
names(metadata)[names(metadata) == variable] <- "Group"
ratio_mat <- aggregate(. ~ Group, ratio_mat, mean)
ratio_mat <- ratio_mat[1:(length(ratio_mat)-1)]
}
#'expand the dataframe into more rows with fewer columns for graphing
ratio_mat <- reshape2::melt(data = ratio_mat, value.name = "ASV_Count")
return(ratio_mat)
}
#'make an abundance table for downstream graphing and also interactive analysis for Hannah/Andreas
abundance_table <- function(ps_object, species, combine) {
#'determine which taxonomic levels to include
if(species==TRUE){
cols = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
}else if (species==FALSE){
cols = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus")
}
#pull out OTU table, transpose, and move rownames to a column of OTU values
OTU = as(otu_table(ps_object), "matrix")
OTU = t(OTU)
OTU = as.data.frame(OTU)
OTU <- rownames_to_column(OTU, var = "OTU")
#melt phyloseq object into a data frame, create new taxon column of pasted
#taxa values, match taxon column to OTU data frame using OTU identifiers
melted_ps <- psmelt(ps_object)
melted_ps$taxon <- apply(melted_ps[,cols], 1, paste, collapse = ";")
OTU$taxon <- melted_ps$taxon[match(OTU$OTU, melted_ps$OTU)]
#'either combine ASVs by taxonomic metadata if the same or keep unique ASVs
if(combine == TRUE){
OTU$taxon <- as.character(OTU$taxon)
OTU <- OTU[,-1]
OTU <- aggregate(. ~ taxon, OTU, sum)
OTU$OTU <- melted_ps$OTU[match(OTU$taxon, melted_ps$taxon)]
}else if(combine == FALSE){
OTU = OTU
}
#'Match taxonomic metadata to ASVs
if (species == TRUE){
OTU$Kingdom <- melted_ps$Kingdom[match(OTU$OTU, melted_ps$OTU)]
OTU$Phylum <- melted_ps$Phylum[match(OTU$OTU, melted_ps$OTU)]
OTU$Class <- melted_ps$Class[match(OTU$OTU, melted_ps$OTU)]
OTU$Order <- melted_ps$Order[match(OTU$OTU, melted_ps$OTU)]
OTU$Family <- melted_ps$Family[match(OTU$OTU, melted_ps$OTU)]
OTU$Genus <- melted_ps$Genus[match(OTU$OTU, melted_ps$OTU)]
OTU$Species <- melted_ps$Species[match(OTU$OTU, melted_ps$OTU)]
OTU$Kingdom <- paste("k", OTU$Kingdom, sep="_")
OTU$Phylum <- paste("p", OTU$Phylum, sep="_")
OTU$Class <- paste("c", OTU$Class, sep="_")
OTU$Order <- paste("o", OTU$Order, sep="_")
OTU$Family <- paste("f", OTU$Family, sep="_")
OTU$Genus <- paste("g", OTU$Genus, sep="_")
OTU$Species <- paste("s", OTU$Species, sep="_")
}else if (species == FALSE){
OTU$Kingdom <- melted_ps$Kingdom[match(OTU$OTU, melted_ps$OTU)]
OTU$Phylum <- melted_ps$Phylum[match(OTU$OTU, melted_ps$OTU)]
OTU$Class <- melted_ps$Class[match(OTU$OTU, melted_ps$OTU)]
OTU$Order <- melted_ps$Order[match(OTU$OTU, melted_ps$OTU)]
OTU$Family <- melted_ps$Family[match(OTU$OTU, melted_ps$OTU)]
OTU$Genus <- melted_ps$Genus[match(OTU$OTU, melted_ps$OTU)]
OTU$Kingdom <- paste("k", OTU$Kingdom, sep="_")
OTU$Phylum <- paste("p", OTU$Phylum, sep="_")
OTU$Class <- paste("c", OTU$Class, sep="_")
OTU$Order <- paste("o", OTU$Order, sep="_")
OTU$Family <- paste("f", OTU$Family, sep="_")
OTU$Genus <- paste("g", OTU$Genus, sep="_")
}
return(OTU)
}
View(Dog_abundance_tab)
View(Dog_asv_freq)
View(Dog_abundance_tab)
RA_table <- function(phyloseq, glom_level, taxa){
#' perform the function for selected taxa
if (!missing(taxa)){
#'remove zeros
data <- prune_taxa(taxa_sums(phyloseq) > 0, phyloseq)
#'glomerate taxa to chosen level, i.e. Class, Phylum etc
data = tax_glom(data, glom_level)
#'Transform all reads to ratio. note: this will make whatever taxa you select be a percentage
#'of the total even though we are throwing out unselected taxa
data = transform_sample_counts(data, function(x) 100 * x/sum(x))
#'melt phyloseq object into a dataframe, clean it up, and select specified taxa
data_tab <- psmelt(data)
data_tab = data_tab[, c(tail(seq_len(ncol(data_tab)), 1), seq_len(ncol(data_tab) - 1))]
data_tab = data_tab[which(data_tab[,1] %in% taxa),]
return(data_tab)
}
#'this works the same only it does not select specific taxa at the end
else if (missing(taxa)){
data <- prune_taxa(taxa_sums(phyloseq) > 0, phyloseq)
data = tax_glom(data, glom_level)
data = transform_sample_counts(data, function(x) 100 * x/sum(x))
data_tab <- psmelt(data)
taxa = as.character(levels(data_tab[,glom_level]))
data_tab = data_tab[, c(tail(seq_len(ncol(data_tab)), 1), seq_len(ncol(data_tab) - 1))]
data_tab = data_tab[which(data_tab[,1] %in% taxa),]
return(data_tab)
}
}
genus_levels <- levels(Dog_abundance_tab$Genus)
genus_levels <- levels(as.factor(Dog_abundance_tab$Genus))
genus_levels
ps_genus <- tax_glom(ps, taxrank = "Genus")
Top10OTUs <- names(sort(taxa_sums(ps_genus), TRUE)[1:10])
ps_top_10 <- prune_taxa(Top10OTUs, ps_genus)
View(Metadata)
plot_bar(ps_top_10,x = "Sample", y = "Abundance", fill = "Genus", facet_grid = ~Genus)
top_10_genera_bar <- plot_bar(ps_top_10,x = "Sample", y = "Abundance", fill = "Genus", facet_grid = ~Genus)
library(officer)
read_pptx %>%
add_slide() %>%
add_slide()
?add_slide
read_pptx %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(top_10_genera_bar)
read_pptx()x %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(top_10_genera_bar)
read_pptx(path = NULL) %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(top_10_genera_bar)
pptx <- read_pptx(path = NULL)
add_slide(x = pptx, layout = "Title and Content", master = "Office Theme") %>%
ph_with(top_10_genera_bar) %>%
print(pptx, target = "../../../Desktop/dog_test.pptx")
?ph_with
add_slide(x = pptx, layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), top_10_genera_bar) %>%
print(pptx, target = "../../../Desktop/dog_test.pptx")
ASV_richness_pie_chart
ASV_richness_pie_chart <- ASV_richness_pie_chart + ggtitle("ASV_Frequency")
Dog_asv_abundance_pie <- Dog_asv_abundance_pie + ggtitle("ASV_Abundance")
ASV_richness_pie_chart <- ASV_richness_pie_chart + ggtitle("ASV_richness")
Dog_asv_richness_pie
Dog_asv_richness_pie <- Dog_asv_richness_pie + ggtitle("ASV_richness")
Campy_BP
View(Campy_table)
ps_noNA_species <- subset_taxa(ps, !Species=="NA")
plot_bar(ps_noNA_species, x = "Sample", y = "Abundance", fill = "Species") + facet_wrap(.~ Species)
plot_bar(ps_noNA_species, x = "Sample", y = "Abundance", fill = "Species") + facet_wrap(.~ Species, scales = "free")
species_bar <- plot_bar(ps_noNA_species, x = "Sample", y = "Abundance", fill = "Species") + facet_wrap(.~ Species, scales = "free")
pptx <- read_pptx(path = NULL)
add_slide(x = pptx, layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), top_10_genera_bar) %>%
add_slide(x = pptx, layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), Dog_asv_richness_pie) %>%
add_slide(x = pptx, layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), Dog_asv_abundance_pie) %>%
add_slide(x = pptx, layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), species_bar) %>%
print(pptx, target = "../../../Desktop/dog_hannah.pptx")
read_pptx(path = NULL)
read_pptx(path = NULL) %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), top_10_genera_bar) %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), Dog_asv_richness_pie) %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), Dog_asv_abundance_pie) %>%
add_slide(layout = "Title and Content", master = "Office Theme") %>%
ph_with(location = ph_location_fullsize(), species_bar) %>%
print(pptx, target = "../../../Desktop/dog_hannah.pptx")
save.image(file = "Hannah_Dogs_Final.RData")
save.image(file = "../../Hannah_Dogs_Final.RData")
setwd("C:/Users/crtif/Desktop")
setwd("C:/Users/crtif/Desktop/ASVclustr/ASVclustr")
